---
title: "House price prediction algorithm"
author: "Alix Benoit"
date: "6/16/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Setting the working directory
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```



## Introduction

This project uses the Ames Housing Dataset. This dataset includes information about 2930 house sales from 2006 to 2010 in Ames, Iowa, and contains 79 different explanatory variables. It was put together by Dean De Cock from Truman State University; more information about it can be found [here](http://jse.amstat.org/v19n3/decock.pdf).

I acquired this dataset from an ongoing "getting started" kaggle machine learning competion: [House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)

For the purposes of writing this report and calculating my final RMSE, I also downloaded the actual house prices for all entries from the original dataset (Note that this would not be possible if this were not a "getting started competition).

The following libraries were used:  
 - Tidyverse  
 - Caret  
 - Kknn  
 - Rborist

Of the 79 explanatory variables, 43 were identified as categorical and 36 numeric.

The goal of this project is to accurately be able to predict house prices in Ames, Iowa based on a variety of different factors. It is also to learn more about feature engineering/machine learning and to apply skills gained in Harvardx's proffessional certificate program in data science.

The root mean squared error of the log predictions was chosen as the measure of accuracy of the models; the log is taken so that errors on expensive houses will be weighted the same as errors on cheap houses.
$$RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n}{(\ln{\hat{Y_i}} - \ln{Y_i})^2}}$$

In short, the final model was obtained by:  
 - Combining explanatory variables from the given train and test set in order to impute NAs  
 - Splitting full set of explanatory variables back into a train and test set  
 - Obtaining the best measure of center for ratings in the train set.  
 - Fitting a weighted knn model to the numerical variables of the train set, predicting centered rating  
 - Fitting a random forest model to the categorical vriables of the train set, predicting centered rating, minus predictions from the knn model.  

```{r load, include=FALSE}
# Required packages:
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
# if(!require(matrixStats)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(kknn)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(Rborist)) install.packages("caret", repos = "http://cran.us.r-project.org")


# Loading training and testing sets
test <- read.csv("datasets/test.csv")
train <- read.csv("datasets/train.csv")
sample_submission <- read.csv("datasets/sample_submission.csv")
# actual prices for testing purposes:
actual_prices <- read.csv("datasets/full-score.csv")
```

## Method/Analysis
(explains the process and techniques used, including data cleaning, data exploration and visualization, any insights gained, and your modeling approach)

### Data wrangling and cleaning

I acquired the dataset from a competition, therefore it was already split 50/50 into a train set and test set. The train set contains a "Sale Price" column, while the test set does not. Since I need to show my final RMSE in this report I also downloaded the actual test set prices from the public dataset, but I only used it to calculate the RMSE of my final model.




### Baseline model



### Weighted Knn



### Random Forest



## Results



## Conclusion


